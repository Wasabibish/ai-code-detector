{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Notebook\n",
    "\n",
    "This notebook is designed to test different deployment approaches and includes a **Gradio interface**.\n",
    "\n",
    "- **Usage**:\n",
    "  - There is an option `USE_LLM=false` that allows the interface to run normally without downloading the LLM.\n",
    "  - If you wish to set `USE_LLM=true`, the fine-tuned **Gemma 2B** LLM will be downloaded. \n",
    "  \n",
    "  **Note**: This may take time, so it's recommended to use a **GPU** for better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models from huggingface\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_LLM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model_name = 'wasabibish/plagiarism-detection'\n",
    "tokenizer_name = 'distilbert/distilbert-base-uncased-finetuned-sst-2-english'\n",
    "regression_model = AutoModelForSequenceClassification.from_pretrained(regression_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "similarity_model = SentenceTransformer(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_LLM:\n",
    "    llm_id = \"google/gemma-2b-it\"\n",
    "    llm_id_finetuned = \"wasabibish/gemma-2b-it-code-ai-generated\"\n",
    "    llm_tokenizer = AutoTokenizer.from_pretrained(llm_id)\n",
    "    finetuned_llm = AutoModelForCausalLM.from_pretrained(llm_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vector db\n",
    "vector_db = torch.load('vector_db.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_score(sentence1_vector, vector_db,  top_n=3):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the weighted score of a given sentence based on the similarity scores \n",
    "    of the top_n most similar sentences in the vector_db\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    sentence1_vector: np.array\n",
    "        The vector of the sentence for which the weighted score should be calculated\n",
    "    vector_db: dict\n",
    "        A dictionary containing the vectors and scores of the test dataset\n",
    "    top_n: int\n",
    "        The number of most similar sentences to consider\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    weighted_score: float\n",
    "        The weighted score of the sentence\n",
    "    \"\"\"\n",
    "\n",
    "    similarity_scores = {}\n",
    "\n",
    "    # calculate similarity scores for each sentence in the vector_db\n",
    "    for sentence, data in vector_db.items():\n",
    "        vector = data['vector']\n",
    "        score = data['score']\n",
    "        similarity = util.pytorch_cos_sim(sentence1_vector, vector).item()\n",
    "        similarity_scores[sentence] = {\n",
    "            'similarity': similarity,\n",
    "            'score': score\n",
    "        }\n",
    "\n",
    "    # sort sentences based on similarity scores\n",
    "    sorted_similarity_scores = sorted(similarity_scores.items(), key=lambda x: x[1]['similarity'], reverse=True)\n",
    "    most_similar_sentences = sorted_similarity_scores[:top_n]\n",
    "\n",
    "    # calculate the weighted score (similarity * real score)\n",
    "    total_score = 0\n",
    "    total_similarity = 0\n",
    "    for sentence, data in most_similar_sentences:\n",
    "        similarity = data['similarity']\n",
    "        score = data['score']\n",
    "        total_score += similarity * score\n",
    "        total_similarity += similarity\n",
    "\n",
    "    weighted_score = total_score / total_similarity if total_similarity > 0 else 0\n",
    "\n",
    "    return weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sentence, model):\n",
    "    \"\"\"\n",
    "    Get the embedding of a sentence using a given model\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    sentence: str\n",
    "        The sentence to encode\n",
    "    model: SentenceTransformer\n",
    "        The model to use for encoding\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    embedding: np.array\n",
    "        The embedding of the sentence\n",
    "    \"\"\"\n",
    "\n",
    "    embedding = model.encode(sentence)\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_simialrity(question, answer, top_n=3):\n",
    "    \"\"\"\n",
    "    Get the similarity score of a given sentence\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    sentence1: str\n",
    "        The sentence to get the similarity score for\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    similarity_score: float\n",
    "        The similarity score of the sentence\n",
    "    \"\"\"\n",
    "    text = 'Question: ' + question + '\\nAnswer: ' + answer\n",
    "    sentence1_embedding = get_embedding(text, similarity_model)\n",
    "    similarity_score = calculate_weighted_score(sentence1_embedding, vector_db, top_n=top_n)\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferece_regression(question, answer=None):\n",
    "    \"\"\"\"\n",
    "    Function to make predictions on new data\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    question : str\n",
    "        The question text (coding problem)\n",
    "    answer : str\n",
    "        The answer text (solution, given code)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        The predicted plagiarism score\n",
    "    \"\"\"\n",
    "    if answer is None:\n",
    "        text = question\n",
    "    else:\n",
    "        text = 'Question :\\n' + question + '\\nAnswer :\\n' + answer\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = regression_model(**inputs).logits\n",
    "    return logits.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(question, answer):\n",
    "    \"\"\"\n",
    "    Generate a completion for the given question and answer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    question : str\n",
    "        The question to be asked. (coding problem)\n",
    "    answer : str\n",
    "        The answer to the question. (code snippet)\n",
    "    model : transformers.PreTrainedModel\n",
    "        The model to be used for generation.\n",
    "    tokenizer : transformers.PreTrainedTokenizer\n",
    "        The tokenizer to be used for tokenization.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The generated completion.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define prompt template\n",
    "    prompt_template = \"\"\"\n",
    "    <start_of_turn>user :\n",
    "      Is this code AI-generated? Provide a score between 0 and 1, where 0 means not AI-generated and 1 means fully AI-generated.\n",
    "\n",
    "      Question: {question}\n",
    "      Answer: {answer}\n",
    "\n",
    "    <end_of_turn>\\n<start_of_turn>model :\n",
    "    \"\"\"\n",
    "\n",
    "    # format prompt with query\n",
    "    prompt = prompt_template.format(question=question, answer=answer)\n",
    "\n",
    "    # tokenize prompt\n",
    "    encodeds = llm_tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "    # Move inputs to device - ensure model inputs are on the same device as the model\n",
    "    model_inputs = encodeds.to(finetuned_llm.device)\n",
    "\n",
    "    # Generate response\n",
    "    generated_ids = finetuned_llm.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # decode response to human readable text\n",
    "    decoded = llm_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_output(output):\n",
    "    # Extract the score using regular expressions\n",
    "    pattern = r\"(\\d+\\.?\\d)\"  # Matches one or more digits followed by an optional decimal point and more digits\n",
    "    # get all the matches\n",
    "    matches = re.findall(pattern, output)\n",
    "\n",
    "    # Check if any matches were found\n",
    "    if not matches:\n",
    "        return None\n",
    "    # Convert the matches to floats\n",
    "    scores = [float(match) for match in matches]\n",
    "\n",
    "    return scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plagiarism_score(question, answer):\n",
    "    # Generate completion\n",
    "    result = get_completion(question=question, answer=answer)\n",
    "\n",
    "    # Post-process the output\n",
    "    score = post_process_output(result)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plagiarism_detection(question, answer, gemma_llm=False):\n",
    "\n",
    "    similarity_score = get_score_simialrity(question, answer, 2)\n",
    "    regression_score = inferece_regression(question, answer)\n",
    "    if gemma_llm:\n",
    "        llm_score = get_plagiarism_score(question, answer)\n",
    "        return llm_score, similarity_score, regression_score\n",
    "    else:\n",
    "        return None, similarity_score, regression_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(\n",
    "    fn=plagiarism_detection,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Question\", interactive=True),\n",
    "        gr.Textbox(label=\"Answer\", interactive=True),\n",
    "        gr.Checkbox(label=\"Use Gemma LLM\")],\n",
    "    outputs=[gr.Textbox(label=\"LLM Score\"), gr.Textbox(label=\"Similarity Score\"), gr.Textbox(label=\"Regression Score\")],\n",
    "    title=\"Plagiarism Detection\",\n",
    "    description=\"Detect plagiarism in code using a combination of regression and similarity scores.\",\n",
    "    examples=[\n",
    "        [data['question'][55], data['human_content'][55]],\n",
    "        [data['question'][75], data['llm_content'][75]]\n",
    "    ]\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
